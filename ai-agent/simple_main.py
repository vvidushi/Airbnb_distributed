from typing import Optional
import os
import requests
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv
import uvicorn

# Load environment variables
load_dotenv()

# Initialize FastAPI app
app = FastAPI(title="AI Travel Assistant", version="1.0.0")

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],  # Frontend URLs
    allow_credentials=True,
    allow_methods=["*"],  # Allow all methods
    allow_headers=["*"],  # Allow all headers
)

# OpenAI Configuration
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")
OPENAI_TEMPERATURE = float(os.getenv("OPENAI_TEMPERATURE", "0.3"))
OPENAI_MAX_TOKENS = int(os.getenv("OPENAI_MAX_TOKENS", "2000"))

# Tavily Configuration
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
TAVILY_BASE_URL = "https://api.tavily.com"

# Backend Configuration
BACKEND_URL = os.getenv("BACKEND_URL", "http://localhost:5001")
INTERNAL_API_KEY = os.getenv("INTERNAL_API_KEY", "airbnb_internal_key_2024")

# Debug: Print the API key being used
print(f"ğŸ”‘ Internal API Key: {INTERNAL_API_KEY}")

# Initialize services
USE_OPENAI = bool(OPENAI_API_KEY)
USE_TAVILY = bool(TAVILY_API_KEY)

if USE_OPENAI:
    print(f"âœ… OpenAI initialized ({OPENAI_MODEL})")
else:
    print("âš ï¸ OpenAI API key not set. Using rule-based responses only.")

if USE_TAVILY:
    print("âœ… Tavily initialized (web search enabled)")
else:
    print("âš ï¸ Tavily API key not set. Web search disabled.")

# Request/Response Models
class AIRequest(BaseModel):
    query: str
    userId: Optional[str] = None  # Make userId optional
    
    class Config:
        # Allow extra fields to be ignored
        extra = "ignore"

class AIResponse(BaseModel):
    response: str

def fetch_user_bookings(user_id: str = None):
    """Dynamically fetch user bookings from backend database"""
    bookings = []
    if not user_id:
        return bookings  # Return empty list if no user ID
    
    try:
        headers = {
            "x-internal-api-key": INTERNAL_API_KEY
        }
        print(f"ğŸ”‘ Using API key: {INTERNAL_API_KEY[:10]}...")
        print(f"ğŸŒ Requesting: {BACKEND_URL}/api/bookings/internal/traveler?userId={user_id}")
        backend_response = requests.get(
            f"{BACKEND_URL}/api/bookings/internal/traveler",
            params={"userId": user_id},
            headers=headers,
            timeout=5
        )
        
        if backend_response.status_code == 200:
            bookings = backend_response.json()
            print(f"ğŸ“… Fetched {len(bookings)} bookings for user {user_id}")
        else:
            print(f"âš ï¸ Could not fetch bookings: HTTP {backend_response.status_code}")
    except Exception as e:
        print(f"âš ï¸ Could not fetch bookings: {e}")
    
    return bookings

def search_tavily(query: str):
    """Use Tavily for web search as required in homework"""
    web_data = ""
    try:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {TAVILY_API_KEY}"
        }
        
        data = {
            "query": query,
            "max_results": 5
        }
        
        response = requests.post(
            f"{TAVILY_BASE_URL}/search",
            headers=headers,
            json=data,
            timeout=10
        )
        
        if response.status_code == 200:
            results = response.json()
            if results and results.get('results'):
                web_data = "\n\nLive web information:\n"
                for r in results['results']:
                    web_data += f"- {r.get('title', '')}: {r.get('content', '')[:200]}...\n"
            print(f"ğŸ” Tavily search completed for: {query[:60]}")
        else:
            print(f"âš ï¸ Tavily search error: {response.status_code}")
    except Exception as e:
        print(f"âš ï¸ Tavily search error: {e}")
    
    return web_data

def call_openai(prompt: str):
    """Call OpenAI API to generate AI response"""
    print(f"ğŸ¤– Calling OpenAI API")
    print(f"ğŸ“¦ Using model: {OPENAI_MODEL}")
    print("ğŸ”„ Processing request with OpenAI...")
    
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json"
    }

    data = {
        "model": OPENAI_MODEL,
        "messages": [
            {"role": "system", "content": "You are an intelligent AI travel assistant for an Airbnb-like platform."},
            {"role": "user", "content": prompt}
        ],
        "temperature": OPENAI_TEMPERATURE,
        "max_tokens": OPENAI_MAX_TOKENS
    }

    response = requests.post(
        "https://api.openai.com/v1/chat/completions",
        headers=headers,
        json=data,
        timeout=30
    )

    if response.status_code == 200:
        result = response.json()
        ai_response = result["choices"][0]["message"]["content"]
        print(f"âœ… OpenAI response generated successfully")
        return ai_response
    elif response.status_code == 429:
        error_data = response.json()
        if "quota" in error_data.get("error", {}).get("message", "").lower():
            return (
                "I'm currently experiencing high demand and my quota has been exceeded. "
                "Please try again later, or contact support if this persists."
            )
        else:
            print(f"âš ï¸ OpenAI API rate limit error")
            raise Exception(f"OpenAI API rate limit: {response.text}")
    else:
        print(f"âš ï¸ OpenAI API error: HTTP {response.status_code}")
        raise Exception(f"OpenAI API error: {response.status_code} - {response.text}")

@app.post("/api/ai/plan", response_model=AIResponse)
async def ai_plan(request: AIRequest):
    """
    Main AI endpoint - Flow:
    1. Fetch user bookings (from backend database)
    2. Call TAVILY (web search) - Gets real-time data
    3. Build prompt combining: User query + Booking context + Tavily web data
    4. Call OpenAI API - Generates response
    5. FastAPI returns response to user
    """
    
    print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print(f"ğŸ“¥ User Request Received")
    print(f"   Query: '{request.query}'")
    print(f"   UserId: '{request.userId}'")
    print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    
    # Step 1: Fetch user bookings (from backend database)
    print(f"\n[Step 1] ğŸ” Fetching user bookings from backend database...")
    bookings = fetch_user_bookings(request.userId)
    print(f"âœ… Retrieved {len(bookings)} booking(s) for user")
    
    # Use OpenAI for intelligent query analysis and response generation
    if USE_OPENAI:
        try:
            # Prepare context with user's bookings
            context = ""
            if bookings:
                context = f"User has {len(bookings)} booking(s). "
                for i, booking in enumerate(bookings):  
                    location = booking.get('location') or booking.get('city', 'destination')
                    status = booking.get('status', 'unknown')
                    start_date = booking.get('start_date', '')[:10] if booking.get('start_date') else 'N/A'
                    end_date = booking.get('end_date', '')[:10] if booking.get('end_date') else 'N/A'
                    context += f"Booking {i+1}: {location} ({start_date} to {end_date}) - Status: {status}. "
            
            # Step 2: Call TAVILY (web search) - Gets real-time data
            # - Current weather
            # - Local events  
            # - Restaurant info
            # - Tourist attractions
            print(f"\n[Step 2] ğŸŒ Calling TAVILY (web search) for real-time data...")
            web_data = ""
            if USE_TAVILY:
                # Smart search query generation
                search_query = request.query
                
                # Enhance search for travel-related queries
                if any(word in request.query.lower() for word in ["weather", "forecast", "temperature"]):
                    if bookings:
                        upcoming_trip = bookings[0]
                        location = upcoming_trip.get('location') or upcoming_trip.get('city', '')
                        start_date = upcoming_trip.get('start_date', '')[:10] if upcoming_trip.get('start_date') else ''
                        if location and start_date:
                            search_query = f"weather forecast {location} {start_date}"
                
                web_data = search_tavily(search_query)
                print(f"âœ… Tavily search completed - Retrieved live web data")
            else:
                print(f"âš ï¸ Tavily not configured - Skipping web search")
            
            # Step 3: Build prompt combining:
            # - User query
            # - Booking context
            # - Tavily web data
            print(f"\n[Step 3] ğŸ“ Building prompt combining user query + booking context + Tavily data...")
            prompt = f"""You are an intelligent AI travel assistant for an Airbnb-like platform.

{context}

User query: {request.query}
{web_data}

Instructions:
1. If the user is asking about their trips/bookings, provide specific information using the booking data above
2. If the user is asking for travel planning/recommendations, provide detailed day-by-day plans with:
   - Morning/afternoon/evening activities
   - Specific locations with addresses
   - Duration estimates
   - Restaurant recommendations
   - Packing checklists (weather-aware if weather data provided)
3. Use the live web information above to enhance your responses
4. Be helpful, specific, and practical

Respond with a comprehensive, helpful answer."""
            print(f"âœ… Prompt built successfully ({len(prompt)} characters)")
            
            # Step 4: Call OpenAI API - Generates response
            # - Reads all context
            # - Creates personalized answer
            # - Formats response nicely
            print(f"\n[Step 4] ğŸ¤– Calling OpenAI API to generate response...")
            ai_response = call_openai(prompt)
            print(f"âœ… OpenAI ({OPENAI_MODEL}) response generated successfully")
            print(f"   Response length: {len(ai_response)} characters")
            
            # Limit response length for chat
            if len(ai_response) > 2000:
                ai_response = ai_response[:1997] + "..."
            
            # Step 5: FastAPI returns response to user
            print(f"\n[Step 5] ğŸ“¤ Returning response to user...")
            print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            return {"response": ai_response.strip()}

        except Exception as e:
            print(f"\nâš ï¸ OpenAI error: {e}. Falling back to basic response.")
            return {
                "response": (
                    "Sorry, I'm having trouble with my AI brain right now. "
                    "But I can still help! Try asking about:\n"
                    "â€¢ Your trips and bookings\n"
                    "â€¢ Travel planning and recommendations\n"
                    "â€¢ Weather information\n"
                    "â€¢ Or just say hi! ğŸ‘‹"
                )
            }
    
    # Fallback for when OpenAI is not available
    return {
        "response": (
            "I'm currently unable to process your request. "
            "Please make sure OpenAI API is properly configured. "
            "You can still browse properties and make bookings!"
        )
    }

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "openai_configured": USE_OPENAI,
        "tavily_configured": USE_TAVILY,
        "model": OPENAI_MODEL if USE_OPENAI else "none"
    }

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
